{
 "cells": [
  {
   "cell_type": "code",
   "id": "18bb6840dd32e956",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-19T02:38:25.216880Z",
     "start_time": "2025-03-19T02:38:22.260227Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import ipywidgets as widgets\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import display"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "4b024b98d9ba65a6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-19T02:38:25.224159Z",
     "start_time": "2025-03-19T02:38:25.220158Z"
    }
   },
   "source": [
    "feature_names = {\n",
    "  0: 'hair',\n",
    "  1: 'feathers', \n",
    "  2: 'eggs',  \n",
    "  3: 'milk', \n",
    "  4: 'airborne', \n",
    "  5: 'aquatic', \n",
    "  6: 'predator', \n",
    "  7: 'toothed', \n",
    "  8: 'backbone',\n",
    "  9: 'breathes',  \n",
    "  10: 'venomous',\n",
    "  11: 'fins', \n",
    "  12: 'legs', \n",
    "  13: 'tail', \n",
    "  14: 'domestic', \n",
    "  15: 'catsize'}"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "59c9aedb1f1ac7a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T02:38:25.321389Z",
     "start_time": "2025-03-19T02:38:25.307313Z"
    }
   },
   "source": [
    "class HGNAM(nn.Module):\n",
    "    def __init__(\n",
    "          self,\n",
    "          in_channels,\n",
    "          out_channels,\n",
    "          num_layers,\n",
    "          hidden_channels=None,\n",
    "          bias=True,\n",
    "          dropout=0.0,\n",
    "          device='cuda',\n",
    "          limited_m=True,\n",
    "          normalize_m=True,\n",
    "          m_per_feature=False,\n",
    "          weight = False,\n",
    "          aggregation = \"overall\"\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.bias = bias\n",
    "        self.dropout = dropout\n",
    "        self.limited_m = limited_m\n",
    "        self.normalize_m = normalize_m\n",
    "        self.m_per_feature = m_per_feature\n",
    "        self.weight = weight\n",
    "        self.aggregation = aggregation\n",
    "        if self.weight == True:\n",
    "            self.feature_weights = nn.Parameter(torch.rand(self.in_channels))\n",
    "\n",
    "        # shape functions f_k\n",
    "        self.fs = nn.ModuleList()\n",
    "        for _ in range(in_channels):\n",
    "            if num_layers == 1:\n",
    "                layers = [nn.Linear(1, out_channels, bias=bias)]\n",
    "            else:\n",
    "                layers = [nn.Linear(1, hidden_channels, bias=bias), nn.ReLU(), nn.Dropout(p=dropout)]\n",
    "                for _ in range(1, num_layers - 1):\n",
    "                    layers += [nn.Linear(hidden_channels, hidden_channels, bias=bias), nn.ReLU(), nn.Dropout(p=dropout)]\n",
    "                layers.append(nn.Linear(hidden_channels, out_channels, bias=bias))\n",
    "            self.fs.append(nn.Sequential(*layers))\n",
    "\n",
    "        # distance functions \\rho\n",
    "        if m_per_feature:\n",
    "            self.ms = nn.ModuleList()\n",
    "            for _ in range(out_channels if limited_m else in_channels):\n",
    "                if num_layers == 1:\n",
    "                    m_layers = [nn.Linear(1, out_channels, bias=bias)]\n",
    "                else:\n",
    "                    m_layers = [nn.Linear(1, hidden_channels, bias=bias), nn.ReLU()]\n",
    "                    for _ in range(1, num_layers - 1):\n",
    "                        m_layers += [nn.Linear(hidden_channels, hidden_channels, bias=bias), nn.ReLU()]\n",
    "                    if limited_m:\n",
    "                        m_layers.append(nn.Linear(hidden_channels, 1, bias=bias))\n",
    "                    else:\n",
    "                        m_layers.append(nn.Linear(hidden_channels, out_channels, bias=bias))\n",
    "                self.ms.append(nn.Sequential(*m_layers))\n",
    "        else:\n",
    "            if num_layers == 1:\n",
    "                m_layers = [nn.Linear(1, out_channels, bias=bias)]\n",
    "            else:\n",
    "                m_layers = [nn.Linear(1, hidden_channels, bias=bias), nn.ReLU()]\n",
    "                for _ in range(1, num_layers - 1):\n",
    "                    m_layers += [nn.Linear(hidden_channels, hidden_channels, bias=bias), nn.ReLU()]\n",
    "                if limited_m:\n",
    "                    m_layers.append(nn.Linear(hidden_channels, 1, bias=bias))\n",
    "                else:\n",
    "                    m_layers.append(nn.Linear(hidden_channels, out_channels, bias=bias))\n",
    "            self.m = nn.Sequential(*m_layers)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x, distances, normalization_matrix = inputs.x.to(self.device), inputs.dist_mat.to(self.device), inputs.norm_mat.to(self.device)\n",
    "        fx = torch.empty(x.size(0), x.size(1), self.out_channels).to(self.device)\n",
    "        for feature_index in range(x.size(1)):\n",
    "            feature_col = x[:, feature_index].view(-1, 1)\n",
    "            fx[:, feature_index] = self.fs[feature_index](feature_col)\n",
    "        if self.weight == True:\n",
    "            attention_weights = F.softmax(torch.exp(self.feature_weights), dim=0)\n",
    "            fx_weighted = fx * attention_weights.unsqueeze(0).unsqueeze(-1)  # (N, num_features, out_channels)\n",
    "            f_sums = fx_weighted.sum(dim=1)\n",
    "        else:\n",
    "            f_sums = fx.sum(dim=1)\n",
    "\n",
    "        if self.aggregation == \"overall\":\n",
    "            m_dist = self.m(distances.flatten().view(-1, 1))\n",
    "            m_dist = m_dist.view(distances.size(0), distances.size(1), self.out_channels)\n",
    "\n",
    "            if self.normalize_m:\n",
    "                m_dist = m_dist / normalization_matrix.unsqueeze(-1)\n",
    "\n",
    "            output = torch.sum(m_dist * f_sums.unsqueeze(0), dim=1)\n",
    "\n",
    "        elif self.aggregation == \"neighbor\":\n",
    "            N = distances.size(0)\n",
    "            out_channels = f_sums.size(1)\n",
    "            self_embedding = f_sums\n",
    "\n",
    "            # distinguish neighbor(distances==0.5 because distances = 1/(real distances + 1))\n",
    "            neighbor_mask = (distances == 0.5)\n",
    "\n",
    "            neighbor_indices = neighbor_mask.nonzero(as_tuple=False)\n",
    "\n",
    "            neighbor_agg = torch.zeros((N, out_channels), device=f_sums.device)\n",
    "            neighbor_agg.index_add_(0, neighbor_indices[:, 0], f_sums[neighbor_indices[:, 1]])\n",
    "\n",
    "            neighbor_counts = neighbor_mask.float().sum(dim=1, keepdim=True)\n",
    "            avg_neighbors = torch.where(neighbor_counts > 0, neighbor_agg / neighbor_counts, torch.zeros_like(neighbor_agg))\n",
    "            output = self_embedding + avg_neighbors\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unknown aggregation type: {}\".format(self.aggregation))\n",
    "        return output\n",
    "\n",
    "    def print_m_params(self):\n",
    "        if hasattr(self, 'm'):\n",
    "            print(\"Single m network parameters:\")\n",
    "            for name, param in self.m.named_parameters():\n",
    "                print(name, param)\n",
    "        elif hasattr(self, 'ms'):\n",
    "            print(\"Separate m networks per dimension:\")\n",
    "            for idx, module in enumerate(self.ms):\n",
    "                for name, param in module.named_parameters():\n",
    "                    print(f\"ms[{idx}].{name}\", param)\n",
    "        else:\n",
    "            print(\"No m parameters found.\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T02:38:25.340815Z",
     "start_time": "2025-03-19T02:38:25.329528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FScorePlotter:\n",
    "    def __init__(self, model, data, data_name, feature_names, class_names, mode='diff'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model: The model object that contains an attribute 'fs',\n",
    "                   a list-like container of feature functions.\n",
    "            data: A torch.Tensor with shape (num_samples, num_features). Used for determining binary features.\n",
    "            feature_names: A list of names (length=num_features) for the features.\n",
    "            class_names: A dict mapping class ids to names.\n",
    "            mode: One of 'f(1)', 'f(0)', or 'diff'. Default is 'diff'.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.data = data\n",
    "        self.data_name = data_name\n",
    "        self.feature_names = feature_names\n",
    "        self.class_names = class_names\n",
    "        self.mode = mode\n",
    "        self.num_features = data.size(1)\n",
    "        self.binary_indices = self.compute_binary_indices()\n",
    "        self.f_scores = self.compute_f_scores_binary(self.mode)\n",
    "        self.last_fig = None  # To store the last plotted figure\n",
    "        \n",
    "        # Create interactive widgets\n",
    "        self.dropdown = widgets.Dropdown(\n",
    "            options=[(f\"{class_id}: {name}\", class_id) for class_id, name in self.class_names.items()],\n",
    "            value=0,\n",
    "            description='Class:',\n",
    "            disabled=False,\n",
    "        )\n",
    "        self.filename_text = widgets.Text(\n",
    "            value='',\n",
    "            placeholder='Enter file name',\n",
    "            description='File Name:',\n",
    "            disabled=False,\n",
    "        )\n",
    "        self.save_button = widgets.Button(\n",
    "            description=\"Save Plot\",\n",
    "            disabled=False,\n",
    "            button_style='',\n",
    "            tooltip='Click to save the current plot',\n",
    "            icon='save'\n",
    "        )\n",
    "        self.save_button.on_click(self.save_plot)\n",
    "    \n",
    "    def compute_f_scores_binary(self, mode='f(1)'):\n",
    "        \"\"\"Compute the f_scores for each feature using the selected mode.\n",
    "        \n",
    "        Args:\n",
    "            mode: 'f(1)' returns the output f(1) for each feature,\n",
    "                  'f(0)' returns f(0), and 'diff' returns f(1)-f(0).\n",
    "        \n",
    "        Returns:\n",
    "            A tensor of shape (num_features, ) containing the computed scores.\n",
    "        \"\"\"\n",
    "        f_scores = []\n",
    "        for i in range(self.num_features):\n",
    "            if mode == 'f(1)':\n",
    "                score = self.model.fs[i].forward(torch.tensor([1.0]).view(-1, 1)).detach().flatten()\n",
    "            elif mode == 'f(0)':\n",
    "                score = self.model.fs[i].forward(torch.tensor([0.0]).view(-1, 1)).detach().flatten()\n",
    "            elif mode == 'diff':\n",
    "                score_1 = self.model.fs[i].forward(torch.tensor([1.0]).view(-1, 1)).detach().flatten()\n",
    "                score_0 = self.model.fs[i].forward(torch.tensor([0.0]).view(-1, 1)).detach().flatten()\n",
    "                score = score_1 - score_0\n",
    "            else:\n",
    "                raise ValueError(\"mode must be one of 'f(1)', 'f(0)', or 'diff'\")\n",
    "            f_scores.append(score)\n",
    "        return torch.stack(f_scores)\n",
    "    \n",
    "    def compute_binary_indices(self):\n",
    "        \"\"\"Detect indices of binary features from self.data.\n",
    "        \n",
    "        Returns:\n",
    "            A list of indices where the number of unique values is <= 2.\n",
    "        \"\"\"\n",
    "        binary_indices = []\n",
    "        num_features = self.data.size(1)\n",
    "        for i in range(num_features):\n",
    "            unique_vals = torch.unique(self.data[:, i])\n",
    "            if unique_vals.numel() <= 2:\n",
    "                binary_indices.append(i)\n",
    "        return binary_indices\n",
    "    \n",
    "    def plot_f_scores(self, selected_class):\n",
    "        \"\"\"Plot a bar chart for binary features based on f_scores for a given class.\n",
    "        \n",
    "        Args:\n",
    "            selected_class: An integer representing the selected class id.\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        # Select the f_scores for the chosen class across binary features\n",
    "        scores = self.f_scores[self.binary_indices, selected_class]\n",
    "        binary_feature_names = [self.feature_names[i] for i in self.binary_indices]\n",
    "        \n",
    "        plt.bar(binary_feature_names, scores.numpy())\n",
    "        plt.xlabel('Binary Features', fontsize=12)\n",
    "        plt.ylabel('f(1) - f(0)', fontsize=12)\n",
    "        plt.xticks(rotation=90, fontsize=10)\n",
    "        plt.yticks(fontsize=10)\n",
    "        plt.title(f'Class: {self.class_names[selected_class]}', fontsize=14)\n",
    "        \n",
    "        self.last_fig = plt.gcf()  # store the current figure\n",
    "        plt.show()\n",
    "    \n",
    "    def save_plot(self, b):\n",
    "        \"\"\"Save the current plot as a PNG file with the provided file name.\"\"\"\n",
    "        fname = self.filename_text.value.strip()\n",
    "        if not fname:\n",
    "            fname = str(self.data_name) + '_' + str(self.class_names[self.dropdown.value]) + '_' + str(self.mode)\n",
    "            print(fname)\n",
    "        elif self.last_fig is None:\n",
    "            print(\"No plot is available to save.\")\n",
    "        directory = \"./plot\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        self.last_fig.savefig(f\"{directory}/{fname}.png\", format=\"png\", bbox_inches=\"tight\")\n",
    "\n",
    "        print(f\"Plot saved as {fname}.png\")\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"Display the interactive widgets and plot.\"\"\"\n",
    "        # Use interact to update the plot based on dropdown selection\n",
    "        widgets.interact(self.plot_f_scores, selected_class=self.dropdown)\n",
    "        # Display the filename textbox and save button below the plot widget\n",
    "        display(self.filename_text, self.save_button)"
   ],
   "id": "a75780274e38aa86",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T02:38:29.106780Z",
     "start_time": "2025-03-19T02:38:25.350182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_name = 'zoo'\n",
    "data_path = f'processed_data/{data_name}.pt'\n",
    "data = torch.load(data_path, weights_only=False)\n",
    "\n",
    "model_dict = 'models/zoo_HGNAM_2732_best_val_acc.pt'\n",
    "model = HGNAM(in_channels=16, hidden_channels=256, num_layers=5, out_channels=7, dropout=0.0, limited_m=0, bias=True, normalize_m=1, weight=True, aggregation='neighbor')\n",
    "model.load_state_dict(torch.load(f\"{model_dict}\", map_location=torch.device('cuda'), weights_only=False))"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T02:38:29.377793Z",
     "start_time": "2025-03-19T02:38:29.116113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class_names = {\n",
    "    0: 'Mammals', 1: 'Birds', 2: 'Reptiles',\n",
    "    3: 'Fish', 4: 'Amphibians', 5: 'Insects', 6: 'Invertebrates'\n",
    "}\n",
    "\n",
    "plotter = FScorePlotter(model, data.x, data_name, feature_names, class_names, mode='f(1)')\n",
    "# plotter = FScorePlotter(model, data.x, data_name, feature_names, class_names, mode='diff')\n",
    "# plotter = FScorePlotter(model, data.x, data_name, feature_names, class_names, mode='f(0)') # you can choose to plot different functions\n",
    "plotter.display()"
   ],
   "id": "b671ec10d4cb79e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interactive(children=(Dropdown(description='Class:', options=(('0: Mammals', 0), ('1: Birds', 1), ('2: Reptileâ€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "02246714b0054f8f913d9a8dde300a26"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(value='', description='File Name:', placeholder='Enter file name')"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f210b409209489e87734c64a88d4403"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Button(description='Save Plot', icon='save', style=ButtonStyle(), tooltip='Click to save the current plot')"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04dbfcf17eba4b5ba4e0cc7691f23e63"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
